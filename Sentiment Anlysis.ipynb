{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da771ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98796052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid_obj = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5754ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(text):\n",
    "    sentiment_dict = sid_obj.polarity_scores(text)\n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22234c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(text):\n",
    "    sentiment_dict = sid_obj.polarity_scores(text)\n",
    "    if sentiment_dict['neg']< sentiment_dict['pos']:\n",
    "        x=1\n",
    "    elif sentiment_dict['neg']> sentiment_dict['pos']:\n",
    "        x=-1\n",
    "    else:\n",
    "        x=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004482a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12845f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "translator = Translator()\n",
    "def translation(text):\n",
    "    time.sleep(2.4)\n",
    "    if validators.url(text):\n",
    "        return text\n",
    "    else:\n",
    "        translated =model.translate(text, target_lang='en')\n",
    "        #translated_text = translator.translate(text)\n",
    "        return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16655b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(data):\n",
    "    data = data[['text','lang']]\n",
    "    data['text_translated']=data[data['lang']!='en'].text.apply(translation)\n",
    "    data.text_translated.fillna(data.text , inplace=True)\n",
    "    data['ploarity']=data.text_translated.apply(polarity)\n",
    "    data['score']=data.text_translated.apply(sent)\n",
    "    data['Subjectivity'] = data['text_translated'].apply(getSubjectivity)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Berkshire_Hathaway_csv_files'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef950a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Amazon_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "Amazon_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    print(data['ploarity'].value_counts())\n",
    "    Amazon_data = Amazon_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                       'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(Amazon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon_data.to_csv('Aamazontweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e626cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\UnitedHealth_Group_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "UH_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    UH_data = UH_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(UH_data)\n",
    "UH_data.to_csv('UHtweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de782f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Procter_Gamble_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "PG_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    PG_data = PG_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(PG_data)\n",
    "PG_data.to_csv('PGtweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Tesla_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "Tesla_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    Tesla_data = Tesla_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(Tesla_data)\n",
    "Tesla_data.to_csv('Teslatweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Nvidia_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "Nvidia_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    Nvidia_data = Nvidia_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(Nvidia_data)\n",
    "Nvidia_data.to_csv('Nvidiatweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Microsoft_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "Microsoft_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    Microsoft_data = Microsoft_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(Microsoft_data)\n",
    "Microsoft_data.to_csv('Microsofttweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\JPMorgan_Chase_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "JP_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    JP_data = JP_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(JP_data)\n",
    "JP_data.to_csv('JPtweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de72fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\ExxonMobil_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "Exxon_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    Exxon_data = Exxon_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(Exxon_data)\n",
    "Exxon_data.to_csv('Exxontweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a17daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Apple_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "Apple_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    #print(data['ploarity'].value_counts())\n",
    "    Apple_data = Apple_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': data['ploarity'].value_counts()[-1]/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(Apple_data)\n",
    "Apple_data.to_csv('Appletweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path =path+'\\\\Csv_files\\\\Berkshire_Hathaway_csv_files'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "Berkshire_Hathaway_data = pd.DataFrame(columns = ['Date', 'Avg_Compound', 'Subjectivity', 'Per_pos', 'Per_neg'])\n",
    "#Create\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    data = sentiment(df)\n",
    "    \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    date = f.split(\"\\\\\")[-1][:10]\n",
    "    print(data['ploarity'].value_counts())\n",
    "    \n",
    "    Berkshire_Hathaway_data = Berkshire_Hathaway_data.append({'Date' : date, 'Avg_Compound' : data['score'].mean() , 'Subjectivity' : data['Subjectivity'].mean()\n",
    "                                     , 'Per_pos': data['ploarity'].value_counts()[1]/data['ploarity'].count(),\n",
    "                                      'Per_neg': 1-(data['ploarity'].value_counts()[1]+data['ploarity'].value_counts()[0])/data['ploarity'].count()},\n",
    "        ignore_index = True)\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    #display(df)\n",
    "    print()\n",
    "display(Berkshire_Hathaway_data)\n",
    "Berkshire_Hathaway_data.to_csv('Berkshire.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502db906",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.raise_Exception = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
